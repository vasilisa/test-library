{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "associatedRecipe": "compute_test",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1656087967884
    },
    "creator": "admin",
    "createdOn": 1656087967884,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.15",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# create an empty dataset with ID column\n\n# dummy_data \u003d pd.DataFrame(np.random.rand(100, 10))\n# dummy_data[\u0027Id\u0027] \u003d list(range(10))*10\n\n# # # save it to the dataframe\n# inp \u003d dataiku.Dataset(\"test\")\n# inp.write_with_schema(dummy_data)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs and take the input schema to output dataset\n\ninp \u003d dataiku.Dataset(\"test\")\nout \u003d dataiku.Dataset(\"output\")\nout.write_schema_from_dataframe(inp.get_dataframe())"
      ],
      "outputs": []
    },
    {
      "execution_count": 24,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "count \u003d 0 \nwith out.get_writer() as writer:\n    \n    for df in inp.iter_dataframes(chunksize\u003d10): # access the input dataset in the chunks of 10 rows \n        count +\u003d 1\n        print(count)\n        # Make some changes for the columns in the chunk\n        tmp \u003d df.copy() \n        tmp[\u0027Id\u0027] \u003d tmp[\u0027Id\u0027]+1000 # increment the Id by 1000\n        tmp.iloc[0:10] \u003d np.round(tmp.iloc[0:10] )\n\n#          print(tmp.head())\n        writer.write_dataframe(tmp)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "1\n     0    1    2    3    4    5    6    7    8    9    Id\n0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1000\n1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1001\n2  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1002\n3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1003\n4  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  1004\n2\n      0    1    2    3    4    5    6    7    8    9    Id\n10  0.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1000\n11  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1001\n12  1.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1002\n13  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1003\n14  0.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1004\n3\n      0    1    2    3    4    5    6    7    8    9    Id\n20  0.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1000\n21  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1001\n22  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1002\n23  0.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1003\n24  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  1004\n4\n      0    1    2    3    4    5    6    7    8    9    Id\n30  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  1000\n31  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1001\n32  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  1.0  1002\n33  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1003\n34  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1004\n5\n      0    1    2    3    4    5    6    7    8    9    Id\n40  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1000\n41  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  1001\n42  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1002\n43  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  1.0  0.0  1003\n44  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1004\n6\n      0    1    2    3    4    5    6    7    8    9    Id\n50  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1000\n51  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  1001\n52  1.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  1002\n53  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1003\n54  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0  1.0  1004\n7\n      0    1    2    3    4    5    6    7    8    9    Id\n60  0.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1000\n61  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1001\n62  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0  1002\n63  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1003\n64  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1004\n8\n      0    1    2    3    4    5    6    7    8    9    Id\n70  1.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1000\n71  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1001\n72  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  1002\n73  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1003\n74  0.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1004\n9\n      0    1    2    3    4    5    6    7    8    9    Id\n80  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1000\n81  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1001\n82  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1002\n83  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1003\n84  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1004\n10\n      0    1    2    3    4    5    6    7    8    9    Id\n90  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1000\n91  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1001\n92  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1002\n93  1.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  1003\n94  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1004\n100 rows successfully written (NSqwPLkAVw)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 23,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "count"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "10"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# for some of the IDs we want to replace the content\n# for i in range(5):\n\n# #    tmp \u003d dummy_data[dummy_data[\u0027Id\u0027] \u003d\u003d i] * i\n#     tmp \u003d np.round(dummy_data[dummy_data[\u0027Id\u0027] \u003d\u003d i] * (i+1000))\n\n#     with dataiku.Dataset(\"test\").get_writer() as writer:\n\n#         for (origin,count) in tmp.items():\n#             print(count)\n\n#             writer.write_row_array((origin,count))"
      ],
      "outputs": []
    }
  ]
}